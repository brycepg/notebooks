{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Github statistics from PyPI packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "* Python 3.5+ only\n",
    "* ~1GB spare ram\n",
    "* 7 minutes of waiting (for github & pypi)\n",
    "\n",
    "#### External packages\n",
    "\n",
    "Run `pip install pandas bs4 requests joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en_US.UTF8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools  import islice\n",
    "from urllib.parse import urlparse\n",
    "from typing import List, Iterable, Dict, Union, Tuple, Callable, Any\n",
    "import datetime\n",
    "import json\n",
    "import locale\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "BeautifulSoup = bs4.BeautifulSoup\n",
    "\n",
    "# I use this locale to interperate the comma separated starred count on github.\n",
    "# Is github locale dependent?\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup logging with H:M:S + milliseconds time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyFormatter(logging.Formatter):\n",
    "    def formatTime(self, record):\n",
    "        ct = datetime.datetime.fromtimestamp(record.created)\n",
    "        t = ct.strftime(\"%H:%M:%S\")\n",
    "        s = \"%s,%03d\" % (t, record.msecs)\n",
    "        return s\n",
    "fmt = MyFormatter(\"%(asctime)s: %(message)s\")\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(fmt)\n",
    "handler.setLevel(logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "log.handlers = []\n",
    "log.setLevel(logging.INFO)\n",
    "log.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timeit(func: Callable) -> Callable:\n",
    "    \"\"\"Decorator for timing functions.\"\"\"\n",
    "    def timed(*args: Any, **kw: Any) -> Any:\n",
    "        start = time.time()\n",
    "        result = func(*args, **kw)\n",
    "        end = time.time()\n",
    "        print('%r: %2.2f sec' % (func.__name__, end-start))\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Functions which extract data from pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def get_pypi_table(pypi_topic_listing_url: str) -> bs4.element.Tag:\n",
    "    \"\"\"Take pypi classifier package list, and return the table body BeautifulSoup object.\n",
    "    \n",
    "    Args:\n",
    "        pypi_topic_listing_url: fully qualified url to the pypi package listing.\n",
    "        e.g. 'https://pypi.python.org/pypi?:action=browse&show=all&c=595'\n",
    "        \n",
    "    Returns:\n",
    "        A bs4.element.Tag which is the <tbody> tag from \n",
    "        the `pypi_topic_listing` html source.\n",
    "    \"\"\"\n",
    "    response = requests.get(pypi_topic_listing_url)\n",
    "    content = BeautifulSoup(response.content, \"lxml\")\n",
    "    link_table = content.find(\"table\", attrs={\"class\": \"list\"})\n",
    "    tbody = content.findChild(\"tbody\")\n",
    "    return tbody\n",
    "\n",
    "\n",
    "def yield_valid_links(pypi_tbody: bs4.element.Tag) -> Iterable[str]:\n",
    "    \"\"\"Get valid links from the pypi table body.\n",
    "    \n",
    "    Note:\n",
    "        Some of the table rows do not contain packages/links\n",
    "    \n",
    "    Args:\n",
    "        tbody: The table body of a Pypi classifier list.\n",
    "    \n",
    "    Yields:\n",
    "        hrefs from the python packages inside `tbody`.\n",
    "        They only contain the path from the web root.\n",
    "    \"\"\"\n",
    "    for child in pypi_tbody.childGenerator():\n",
    "        try:\n",
    "            yield child.find(\"a\").attrs[\"href\"]\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "\n",
    "def get_link_contents(pypi_package_href: str) -> dict:\n",
    "    \"\"\"Take href of package, get pypi json data.\n",
    "    \n",
    "    Args:\n",
    "        href(str): A url path, excluding everything else including the host.\n",
    "            Should be a url to a pypi package.\n",
    "            E.g. '/pypi/12factor-vault/'\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of the json found for the package.\n",
    "    \"\"\"\n",
    "    url = \"https://pypi.python.org{href}json\".format(href=pypi_package_href)\n",
    "    response = requests.get(url)\n",
    "    return json.loads(response.content.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here I use the pypi table for python 3 exclusive packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'get_pypi_table': 0.69 sec\n"
     ]
    }
   ],
   "source": [
    "# Does IO\n",
    "tbody = get_pypi_table(\"https://pypi.python.org/pypi?:action=browse&show=all&c=595\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading from pypi is embarassingly slow without parallelization\n",
    "\n",
    "Sorry pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'retrieve_pypi_json_dicts': 34.56 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def retrieve_pypi_json_dicts(tbody):\n",
    "    link_list = yield_valid_links(tbody)\n",
    "    pypi_json_dicts = Parallel(n_jobs=32)(delayed(get_link_contents)(link) for link in link_list)\n",
    "    return pypi_json_dicts\n",
    "\n",
    "# IO here. This took me about 30 seconds. Without parallelization it takes minutes.\n",
    "pypi_json_dicts = retrieve_pypi_json_dicts(tbody)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code which for downloading github info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_github_path(path: str) -> str:\n",
    "    \"\"\"Normalize github path to the main repository\n",
    "    \n",
    "    Args:\n",
    "        path: A path which points to a github repo or\n",
    "            a subdirectory of a github repo\n",
    "    Returns:\n",
    "        A path which points to a github repo\n",
    "    \n",
    "    Some github links point to a wiki\n",
    "    \n",
    "    >>> normalize_github_path('/foo/bar/baz')\n",
    "    '/foo/bar'\n",
    "    >>> normalize_github_path('/foo/bar')\n",
    "    '/foo/bar'\n",
    "    \"\"\"\n",
    "    depth = path.count(\"/\")\n",
    "    if depth > 2:\n",
    "        path = '/'.join(path.split(\"/\")[:3])\n",
    "    return path\n",
    "    \n",
    "\n",
    "def yield_valid_github_url(pypi_json_dicts: Iterable[dict]) -> Iterable[str]:\n",
    "    \"\"\"Yield homepage urls that are pointing to github.\n",
    "    \n",
    "    Args:\n",
    "        pypi_json_dicts: A container of json dictionaries for each pypi package\n",
    "        \n",
    "    Yields:\n",
    "        A fully qualified url for pypi packages\n",
    "        that have a github url as their homepage.\n",
    "        \"\"\"\n",
    "    for pypi_json in pypi_json_dicts:\n",
    "        url = pypi_json[\"info\"][\"home_page\"]\n",
    "        parse_result = urlparse(url)\n",
    "        repo_path = normalize_github_path(parse_result.path)\n",
    "        if parse_result.netloc == \"github.com\":\n",
    "            url = \"https://github.com{}\".format(repo_path)\n",
    "            yield url\n",
    "\n",
    "def yield_github_soup(github_urls: Iterable[str]) -> Tuple[Iterable[BeautifulSoup], int]:\n",
    "    \"\"\"Yield github soup for each github url in url list.\n",
    "    \n",
    "    Note:\n",
    "        A least one of the github links on pypi no longer exist.\n",
    "    \n",
    "    Args:\n",
    "        github_urls: A container for github repository urls\n",
    "\n",
    "    Yields:\n",
    "        The parsed BeautifulSoup from url if the resource exists AND\n",
    "        the url itself\n",
    "    \"\"\"\n",
    "    for url in github_urls:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 404:\n",
    "            yield BeautifulSoup(response.content, \"lxml\"), url\n",
    "        else:\n",
    "            log.debug(\"404 for %s\", url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No need for paralellization here. Github throttles\n",
    "\n",
    "I tried to use the github josn api, but immidately hit the rate limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'get_gh_soup_list': 392.73 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def get_gh_soup_list(pypi_json_dicts):\n",
    "    gh_url_container = yield_valid_github_url(pypi_json_dicts)\n",
    "    gh_soup_list = []\n",
    "    # This code will take forever, so printing the url is an alright indication of progress\n",
    "    # Does IO\n",
    "    for gh_soup, url in yield_github_soup(gh_url_container):\n",
    "        log.debug(\"url: %s\", url)\n",
    "        gh_soup_list.append((gh_soup, url))\n",
    "    return gh_soup_list\n",
    "\n",
    "gh_soup_list = get_gh_soup_list(pypi_json_dicts)\n",
    "\n",
    "# All done with retrieving data from urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 1109 packages\n",
      "734 had valid github urls\n"
     ]
    }
   ],
   "source": [
    "print(\"There were %s packages\" % len(pypi_json_dicts))\n",
    "print(\"%s had valid github urls\" % len(gh_soup_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code which scrapes data from Github\n",
    "\n",
    "Scraping Github is non-ideal since the data is somewhat inconsistent. The alternative would to to check each download for unavailable data, and retry if there is any, however I don't think the missing data is to important to lengthen the download time any more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_contributors(gh_soup: BeautifulSoup,\n",
    "                     contributors_regex=re.compile(\"contributors\")) -> str:\n",
    "    \"\"\"Retrieve number of contributors from github source\n",
    "    \n",
    "    Args:\n",
    "        gh_soup: The parsed source of a github repository in a BeautifulSoup\n",
    "    Returns:\n",
    "          A string since this metric may not be available in which\n",
    "          case an empty string will need to be returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return gh_soup.find(text=contributors_regex).previous.strip()\n",
    "    except (TypeError, AttributeError) as e:\n",
    "        # Github sometimes doesn't load the contributors for some reason\n",
    "        log.debug(\"contributors exception %s\", e)\n",
    "        return \"\"\n",
    "\n",
    "def get_starred_count(gh_soup: BeautifulSoup,\n",
    "                      starred_substring_regex=re.compile('starred')) -> int:\n",
    "    \"\"\"Get the number of times a repository has been starred.\"\"\"\n",
    "    return int(locale.atoi(\n",
    "        gh_soup.find(\n",
    "            \"a\", attrs={'aria-label': starred_substring_regex}\n",
    "        ).text.strip()\n",
    "    ))\n",
    "\n",
    "\n",
    "def get_github_description(gh_soup: BeautifulSoup) -> str:\n",
    "    \"\"\"Get the description of a github repository.\"\"\"\n",
    "    parent_about_div = gh_soup.find(\"div\", class_=\"js-details-container\")\n",
    "    if parent_about_div is None:\n",
    "        # This usually means there is no description\n",
    "        return \"\"\n",
    "    about_span = parent_about_div.find(\"span\", itemprop=\"about\")\n",
    "    if about_span is None:\n",
    "        # A missing span occurs when github cannot retireve the description\n",
    "        return \"\"\n",
    "    return about_span.text.strip()\n",
    "\n",
    "\n",
    "def get_last_commit_time(gh_soup: BeautifulSoup) -> str:\n",
    "    \"\"\"Get the last commit time of a github repository.\n",
    "    \n",
    "    For some reason a lot of times, this cannot be retrieved.\n",
    "    \"\"\"\n",
    "    relative_time = gh_soup.find(\"relative-time\")\n",
    "    if relative_time is None:\n",
    "        # For some of the urls, github didn't load a 'last commit' time.\n",
    "        return \"\"\n",
    "    date_str = relative_time.attrs['datetime']\n",
    "    date_struct = datetime.datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    human_readable_date = datetime.datetime.strftime(date_struct, \"%B %d %Y\")\n",
    "    return human_readable_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "github_info = []\n",
    "clean_gh_soup_list = [gh_soup for gh_soup in gh_soup_list if gh_soup is not None and gh_soup[0] is not None]\n",
    "for gh_soup, url in clean_gh_soup_list:\n",
    "    stars = get_starred_count(gh_soup)\n",
    "    description = get_github_description(gh_soup)\n",
    "    last_commit = get_last_commit_time(gh_soup)\n",
    "    contributors = get_contributors(gh_soup)\n",
    "    github_info.append((url, stars, description, last_commit, contributors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing the data via pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(github_info, columns=[\"url\", \"stars\", \"description\", \"last_commit\", \"contributors\"])\n",
    "df_sorted = df.sort_values(by=\"stars\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>stars</th>\n",
       "      <th>description</th>\n",
       "      <th>last_commit</th>\n",
       "      <th>contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>https://github.com/MagicStack/uvloop</td>\n",
       "      <td>2571</td>\n",
       "      <td>Ultra fast implementation of asyncio event loo...</td>\n",
       "      <td>November 28 2016</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>https://github.com/np1/mps-youtube</td>\n",
       "      <td>2071</td>\n",
       "      <td>Terminal based YouTube player and downloader</td>\n",
       "      <td>November 11 2016</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>https://github.com/tdryer/hangups</td>\n",
       "      <td>1231</td>\n",
       "      <td>the first third-party instant messaging client...</td>\n",
       "      <td>December 03 2016</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/yadayada/acd_cli</td>\n",
       "      <td>1113</td>\n",
       "      <td>A command line interface and FUSE filesystem f...</td>\n",
       "      <td>November 24 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>https://github.com/rasguanabana/ytfs</td>\n",
       "      <td>979</td>\n",
       "      <td>YouTube File System</td>\n",
       "      <td>July 31 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>https://github.com/cosven/FeelUOwn</td>\n",
       "      <td>913</td>\n",
       "      <td>nothing but the alternate</td>\n",
       "      <td>October 13 2016</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>https://github.com/BigchainDB/bigchaindb</td>\n",
       "      <td>840</td>\n",
       "      <td>BigchainDB is a scalable blockchain database</td>\n",
       "      <td>December 10 2016</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>https://github.com/jarun/Buku</td>\n",
       "      <td>807</td>\n",
       "      <td>Powerful command-line bookmark manager. Your m...</td>\n",
       "      <td>December 11 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>https://github.com/mschwager/dhcpwn</td>\n",
       "      <td>512</td>\n",
       "      <td>All your IPs are belong to us.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>https://github.com/machinalis/iepy</td>\n",
       "      <td>480</td>\n",
       "      <td>Information Extraction in Python</td>\n",
       "      <td>October 13 2016</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>https://github.com/TomasTomecek/sen</td>\n",
       "      <td>468</td>\n",
       "      <td>Terminal User Interface for docker engine</td>\n",
       "      <td>November 12 2016</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>https://github.com/retext-project/retext</td>\n",
       "      <td>404</td>\n",
       "      <td>ReText: Simple but powerful editor for Markdow...</td>\n",
       "      <td>October 05 2016</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>https://github.com/phaethon/scapy</td>\n",
       "      <td>373</td>\n",
       "      <td>Network packet and pcap file crafting/sniffing...</td>\n",
       "      <td>December 02 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>https://github.com/7sDream/pyqart</td>\n",
       "      <td>355</td>\n",
       "      <td>QArt Python Implementation.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://github.com/aitjcize/cppman</td>\n",
       "      <td>316</td>\n",
       "      <td>C++ 98/11/14 manual pages for Linux/MacOS</td>\n",
       "      <td>September 15 2016</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>https://github.com/jrfonseca/xdot.py</td>\n",
       "      <td>236</td>\n",
       "      <td>Interactive viewer for graphs written in Graph...</td>\n",
       "      <td>November 18 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>https://github.com/llllllllll/lazy_python</td>\n",
       "      <td>214</td>\n",
       "      <td>I will write this later...</td>\n",
       "      <td>November 07 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>https://github.com/brechtm/rinohtype</td>\n",
       "      <td>201</td>\n",
       "      <td>The Python document processor</td>\n",
       "      <td>November 28 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>https://github.com/veeti/manuale</td>\n",
       "      <td>156</td>\n",
       "      <td>A fully manual Let's Encrypt/ACME client</td>\n",
       "      <td>August 27 2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>https://github.com/nchammas/flintrock</td>\n",
       "      <td>145</td>\n",
       "      <td>A command-line tool for launching Apache Spark...</td>\n",
       "      <td>November 21 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>https://github.com/scheibler/khard</td>\n",
       "      <td>129</td>\n",
       "      <td>Console carddav client</td>\n",
       "      <td>September 20 2016</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>https://github.com/vikstrous/pirate-get</td>\n",
       "      <td>128</td>\n",
       "      <td>A command line interface for The Pirate Bay</td>\n",
       "      <td>November 05 2016</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>https://github.com/humangeo/preflyt</td>\n",
       "      <td>108</td>\n",
       "      <td>A lightweight application environment checker</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           url  stars  \\\n",
       "724       https://github.com/MagicStack/uvloop   2571   \n",
       "247         https://github.com/np1/mps-youtube   2071   \n",
       "371          https://github.com/tdryer/hangups   1231   \n",
       "3          https://github.com/yadayada/acd_cli   1113   \n",
       "450       https://github.com/rasguanabana/ytfs    979   \n",
       "639         https://github.com/cosven/FeelUOwn    913   \n",
       "185   https://github.com/BigchainDB/bigchaindb    840   \n",
       "335              https://github.com/jarun/Buku    807   \n",
       "480        https://github.com/mschwager/dhcpwn    512   \n",
       "235         https://github.com/machinalis/iepy    480   \n",
       "138        https://github.com/TomasTomecek/sen    468   \n",
       "131   https://github.com/retext-project/retext    404   \n",
       "704          https://github.com/phaethon/scapy    373   \n",
       "692          https://github.com/7sDream/pyqart    355   \n",
       "29          https://github.com/aitjcize/cppman    316   \n",
       "731       https://github.com/jrfonseca/xdot.py    236   \n",
       "382  https://github.com/llllllllll/lazy_python    214   \n",
       "563       https://github.com/brechtm/rinohtype    201   \n",
       "522           https://github.com/veeti/manuale    156   \n",
       "642      https://github.com/nchammas/flintrock    145   \n",
       "656         https://github.com/scheibler/khard    129   \n",
       "408    https://github.com/vikstrous/pirate-get    128   \n",
       "411        https://github.com/humangeo/preflyt    108   \n",
       "\n",
       "                                           description        last_commit  \\\n",
       "724  Ultra fast implementation of asyncio event loo...   November 28 2016   \n",
       "247       Terminal based YouTube player and downloader   November 11 2016   \n",
       "371  the first third-party instant messaging client...   December 03 2016   \n",
       "3    A command line interface and FUSE filesystem f...   November 24 2016   \n",
       "450                                YouTube File System       July 31 2016   \n",
       "639                          nothing but the alternate    October 13 2016   \n",
       "185       BigchainDB is a scalable blockchain database   December 10 2016   \n",
       "335  Powerful command-line bookmark manager. Your m...   December 11 2016   \n",
       "480                     All your IPs are belong to us.                      \n",
       "235                   Information Extraction in Python    October 13 2016   \n",
       "138          Terminal User Interface for docker engine   November 12 2016   \n",
       "131  ReText: Simple but powerful editor for Markdow...    October 05 2016   \n",
       "704  Network packet and pcap file crafting/sniffing...   December 02 2016   \n",
       "692                        QArt Python Implementation.                      \n",
       "29           C++ 98/11/14 manual pages for Linux/MacOS  September 15 2016   \n",
       "731  Interactive viewer for graphs written in Graph...   November 18 2016   \n",
       "382                         I will write this later...   November 07 2016   \n",
       "563                      The Python document processor   November 28 2016   \n",
       "522           A fully manual Let's Encrypt/ACME client     August 27 2016   \n",
       "642  A command-line tool for launching Apache Spark...   November 21 2016   \n",
       "656                             Console carddav client  September 20 2016   \n",
       "408        A command line interface for The Pirate Bay   November 05 2016   \n",
       "411      A lightweight application environment checker                      \n",
       "\n",
       "    contributors  \n",
       "724            9  \n",
       "247           41  \n",
       "371           28  \n",
       "3                 \n",
       "450               \n",
       "639           12  \n",
       "185           28  \n",
       "335               \n",
       "480               \n",
       "235           12  \n",
       "138            7  \n",
       "131           13  \n",
       "704               \n",
       "692               \n",
       "29            10  \n",
       "731               \n",
       "382               \n",
       "563               \n",
       "522            2  \n",
       "642               \n",
       "656           10  \n",
       "408           14  \n",
       "411               "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100stars = df_sorted[df_sorted.stars > 100]\n",
    "df_100stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing table in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pandas_df_to_markdown_table(df):\n",
    "    \"\"\"Takes a dataframe and creates a markdown object from it.\n",
    "    \n",
    "    The markdown is compatible with reddit's markdown syntax.\n",
    "    \n",
    "    Source:\n",
    "    \n",
    "    - http://stackoverflow.com/questions/33181846/programmatically-convert-pandas-dataframe-to-markdown-table\n",
    "    \"\"\"\n",
    "    from IPython.display import Markdown, display\n",
    "    fmt = ['---' for i in range(len(df.columns))]\n",
    "    df_fmt = pd.DataFrame([fmt], columns=df.columns)\n",
    "    df_formatted = pd.concat([df_fmt, df])\n",
    "    return Markdown(df_formatted.to_csv(sep=\"|\", index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "markdown_obj = pandas_df_to_markdown_table(df_100stars[[\"url\", \"stars\", \"description\", \"last_commit\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I pasted the markdown to reddit -- \n",
    "Here I shortened the url links by injecting markdown links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url|stars|description|last_commit\n",
      "---|---|---|---\n",
      "[MagicStack/uvloop](https://github.com/MagicStack/uvloop)|2571|Ultra fast implementation of asyncio event loop on top of libuv.|November 28 2016\n",
      "[np1/mps-youtube](https://github.com/np1/mps-youtube)|2071|Terminal based YouTube player and downloader|November 11 2016\n",
      "[tdryer/hangups](https://github.com/tdryer/hangups)|1231|the first third-party instant messaging client for Google Hangouts|December 03 2016\n",
      "[yadayada/acd_cli](https://github.com/yadayada/acd_cli)|1113|A command line interface and FUSE filesystem for Amazon (Cloud) Drive|November 24 2016\n",
      "[rasguanabana/ytfs](https://github.com/rasguanabana/ytfs)|979|YouTube File System|July 31 2016\n",
      "[cosven/FeelUOwn](https://github.com/cosven/FeelUOwn)|913|nothing but the alternate|October 13 2016\n",
      "[BigchainDB/bigchaindb](https://github.com/BigchainDB/bigchaindb)|840|BigchainDB is a scalable blockchain database|December 10 2016\n",
      "[jarun/Buku](https://github.com/jarun/Buku)|807|Powerful command-line bookmark manager. Your mini web!|December 11 2016\n",
      "[mschwager/dhcpwn](https://github.com/mschwager/dhcpwn)|512|All your IPs are belong to us.|\n",
      "[machinalis/iepy](https://github.com/machinalis/iepy)|480|Information Extraction in Python|October 13 2016\n",
      "[TomasTomecek/sen](https://github.com/TomasTomecek/sen)|468|Terminal User Interface for docker engine|November 12 2016\n",
      "[retext-project/retext](https://github.com/retext-project/retext)|404|ReText: Simple but powerful editor for Markdown and reStructuredText|October 05 2016\n",
      "[phaethon/scapy](https://github.com/phaethon/scapy)|373|Network packet and pcap file crafting/sniffing/manipulation/visualization security tool (based on scapy) with python3 compatibility|December 02 2016\n",
      "[7sDream/pyqart](https://github.com/7sDream/pyqart)|355|QArt Python Implementation.|\n",
      "[aitjcize/cppman](https://github.com/aitjcize/cppman)|316|C++ 98/11/14 manual pages for Linux/MacOS|September 15 2016\n",
      "[jrfonseca/xdot.py](https://github.com/jrfonseca/xdot.py)|236|Interactive viewer for graphs written in Graphviz's dot language.|November 18 2016\n",
      "[llllllllll/lazy_python](https://github.com/llllllllll/lazy_python)|214|I will write this later...|November 07 2016\n",
      "[brechtm/rinohtype](https://github.com/brechtm/rinohtype)|201|The Python document processor|November 28 2016\n",
      "[veeti/manuale](https://github.com/veeti/manuale)|156|A fully manual Let's Encrypt/ACME client|August 27 2016\n",
      "[nchammas/flintrock](https://github.com/nchammas/flintrock)|145|A command-line tool for launching Apache Spark clusters.|November 21 2016\n",
      "[scheibler/khard](https://github.com/scheibler/khard)|129|Console carddav client|September 20 2016\n",
      "[vikstrous/pirate-get](https://github.com/vikstrous/pirate-get)|128|A command line interface for The Pirate Bay|November 05 2016\n",
      "[humangeo/preflyt](https://github.com/humangeo/preflyt)|108|A lightweight application environment checker|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(r\"(https://github.com/(.*?))\\|\", r\"[\\2](\\1)|\", markdown_obj.data))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
